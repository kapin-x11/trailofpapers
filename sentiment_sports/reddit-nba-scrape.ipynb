{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit NBA scrape\n",
    "This notebook has code to scrape comments for one month of reddit. Original version used a Reddit API, but now I use the `pushshift` API. Pushshift typically yields ~300k comments / month for a month during the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import praw # for direct reddit pull\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrape_reddit_comments as src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrape_player_data as spd\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nba_coach_df.to_csv('d:/data/sentiment_sports/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading submissions for 2014-10\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "league = 'nba'\n",
    "year = 2014\n",
    "month = 10\n",
    "month_df, submissions, comments = src.get_month_pushshift(year,month,31, league)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load\n",
    "Something weird is going on where is throws a `UnicodeDecodeError` when writing to a gzipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_df.to_csv(f'd:/data/sentiment_sports/{league}_reddit_comments/{year}{month:02}-comments_submissions.tsv',\n",
    "                sep = '\\t', encoding = 'utf-8',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape and combine covariate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load URL https://www.basketball-reference.com/coaches/caseydo99c.html\n",
      "Could not load URL https://www.basketball-reference.com/coaches/guokama99c.html\n",
      "Could not load URL https://www.basketball-reference.com/coaches/johnsma99c.html\n",
      "Could not load URL https://www.basketball-reference.com/coaches/mccloja99c.html\n",
      "Could not load URL https://www.basketball-reference.com/coaches/tormoge99c.html\n",
      "Wall time: 4min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "importlib.reload(spd)\n",
    "nba_coach_df = spd.scrape_nba_coaches()\n",
    "nba_coach_df.to_csv('d:/data/sentiment_sports/covariates/nba_coach_performance.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# then hand edit it\n",
    "nba_coach_df.query('season >= 2013')[['Coach']].drop_duplicates().to_csv('d:/data/sentiment_sports/covariates/nba_coach_race.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load URL https://www.pro-football-reference.com/coaches/ParkBu0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/ShawBu0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/LeeHJi0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/HickRe0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/StraRe0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/McMiBo0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/StarLo0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/RamsBu0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/GansFr0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/MacPDi0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/RobeJD0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/TurnBu0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/WillRa0.htm\n",
      "Could not load URL https://www.pro-football-reference.com/coaches/ConkBi0.htm\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(spd)\n",
    "nfl_coach_df = spd.scrape_nfl_coaches()\n",
    "nfl_coach_df.to_csv('d:/data/sentiment_sports/covariates/nfl_coach_performance.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then hand edit it\n",
    "nfl_coach_df.query('year >= 2013')[['Coach']].drop_duplicates().to_csv('d:/data/sentiment_sports/covariates/nfl_coach_race.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create separate .tsv for coach race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PRAW and reddit API to get lots of comments\n",
    "This no longer works due to update of Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client_id = 'wgPHyF8Ogio_dA'\n",
    "secret = '3BkmoB6wVUWzF0wsOSkIxnI-guo'\n",
    "user_agent = 'r/nba race sentiment 0.1 by /u/Umiy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = praw.Reddit(user_agent=user_agent, client_id=client_id, client_secret=secret)\n",
    "r_nba = r.subreddit('nba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_submission( submission):\n",
    "    text = submission.title + '. ' + submission.selftext\n",
    "    creation_date = submission.created\n",
    "    author = submission.author #.name for PRAW\n",
    "    flair = submission.author_flair_text\n",
    "    score = submission.score\n",
    "    return (text, creation_date, author, flair, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_comment( comment):\n",
    "    if hasattr(comment, 'body') and comment.author != None:\n",
    "        text = comment.body\n",
    "        creation_date = comment.created\n",
    "        author = comment.author\n",
    "        flair = comment.author_flair_text\n",
    "        score = comment.score\n",
    "        return (text, creation_date, author, flair, score)\n",
    "    return ('', 1, '', '', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_month(year, month, month_length):\n",
    "    ''' Get comments and submissions for one month. takes ~ 1h 15 minutes.\n",
    "    '''\n",
    "    data_col = ['text', 'timestamp', 'user', 'flair']\n",
    "    print('Downloading submssions for {}-{}'.format(year, month))\n",
    "    month_submissions = [list(r_nba.submissions(datetime(year,month,day).timestamp(), datetime(year,month,day+1).timestamp() )) for day in range(1,month_length)]\n",
    "    month_submissions = [x for day_submissions in month_submissions for x in day_submissions]\n",
    "    \n",
    "    print('Downloaded {} submissions'.format(len(month_submissions)))\n",
    "    ops = [ parse_submission(submission) for submission in month_submissions]\n",
    "    submission_df =(pd.DataFrame(ops, columns=data_col)\n",
    "                      .assign(source = lambda x: 'submission') )\n",
    "    print('Made dataframe of shape {}'.format(submission_df.shape) )\n",
    "    \n",
    "    print('Downloading comments (this could take an hour)')\n",
    "    comments_list = [submission.comments.list() for submission in month_submissions if hasattr(submission, 'comments')]\n",
    "    comments = [ parse_comment(comment) for comments in  comments_list for comment in comments]\n",
    "    print('Downloaded {} comments'.format(len(comments) ) )\n",
    "    comment_df = (pd.DataFrame(comments, columns=data_col)\n",
    "                    .assign(source = lambda x: 'comment') )\n",
    "    return pd.concat([submission_df, comment_df]), ops, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# this no longe works \n",
    "month_df, submissions, comments = get_month(2017, 11, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
