{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why are some athletes more popular than others?\n",
    "## Part II: Calculating sentiment towards players\n",
    "In this project I am using natural language processing to try to understand what factors drive public opinion towards athletes. In part 1 I covered how I scraped the data off of Reddit and other sports websites. In this notebook, part 2, I will cover how I identified which player comments were about; and how to calculate sentiments towards a player. In part 3 I will cover how to use regression models to isolate what drives public opinion.\n",
    "\n",
    "## What are entities and sentiment?\n",
    "In this notebook I am going to use a lot of jargon from natural language processing (NLP). Before diving into how I calculated opinion towards players, let's review a few terms:\n",
    "* Corpus: a corpus is a collection of documents.\n",
    "* Named entity: In NLP, an \"entity\" is basically a noun. Thus a *named* entity is simply a proper noun. The most common named entity in basketball right now is \"LeBron.\"\n",
    "* Named entity recognition (NER): This is the task of identifying which parts of a sentence are named entities. A simple NER model would use things like capitalization to identify named entities. For example, \"Nice assist by Wall,\" would identify the player John Wall. More complicated NER models use part-of-speech tagging or even neural nets to identify named entities.\n",
    "* Sentiment analysis: This is the task of identifying whether a sentence or document has generally positive or negative feelings. Simple models assign a positive or negative value to each word (e.g. \"love\" is a positive word). More complex models assign sentiment for each entity in a document. Sentiment models are often trained to a specific task.\n",
    "\n",
    "## How do we calculate the sentiment towards a player?\n",
    "After scraping data from Reddit, I had a corpus of comments about NBA and NFL players. These comments ranged from short exclamations about specific players (\"Cedi is the GOAT!\"), to longer comments involving multiple named entities (\"JR Smith threw a bowl of chicken tortilla soup at Damon Jones.\").\n",
    "\n",
    "Probably the best way to calculate sentiment towards players would be to use a combined entity-sentiment model. These models parse each sentence for parts of speech and named entities, and assign sentiment towards each named entity. For example, a combined model could take \"LeBron is better than Jordan,\" and assign positive sentiment to LeBron directly. In the end, I did not use these methods for a few reasons: this was my first time doing sentiment analysis, and these models are complicated, so I wanted to start simpler; these models are less interpretable than other models; these models take a looooong time to run, making iteration slower.\n",
    "\n",
    "Instead, I took a two step approach. First, I identified sentences that contained a single named entity for a players; and then I calculated the overall sentiment of that sentence. The downsides to this approach were that I had to throw away a lot of information from sentences that contained multiple named entities; and that it made the assumption that the sentiment of a sentence reflected the sentiment towards the player in the sentence. In the end, though, I had more than enough data to overcome the first obstacle. As for the second, while it might be true that the sentiment of a sentence doesn't always reflect player sentiment, in general the relationship seemed to hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying which athletes a sentence are about\n",
    "### Named entity recognition\n",
    "I took two broad approaches to named entity recognition. First, I used Stanford's SNER package to identify the named entities in a sentence. My other alternative was to start with a list of named entities I cared about (NBA and NFL players), and then simply check to see if these names were present. In this section, I am going to show how to do both ways. \n",
    "\n",
    "This notebook will show an example of how to do this on a single document. I function-ified this process in the module [`sentiment_sports.py`](https://github.com/map222/trailofpapers/blob/sentiment_sports/sentiment_sports/sports_sentiment.py) so you can use it at your leisure.\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import sent_tokenize\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from ast import literal_eval\n",
    "#from sner import Ner\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunking comments into sentences\n",
    "After scraping I had full comments off of Reddit. To get more samples, we can chunk the comments into sentences for analysis using NLTK's `sent_tokenize` function.\n",
    "\n",
    "First, let's start with a typical Cavs fan comment. I use `pandas` DataFrames for everything, so let's use one here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>flair</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cedi is the GOAT! Isaiah Thomas is the worst</td>\n",
       "      <td>CLE</td>\n",
       "      <td>map222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment flair    user\n",
       "0  Cedi is the GOAT! Isaiah Thomas is the worst   CLE  map222"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_df = pd.DataFrame({'comment':['Cedi is the GOAT! Isaiah Thomas is the worst'], 'user': ['map222'], 'flair':'CLE'})\n",
    "comment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tokenize, I used NLTK's `sent_tokenize` function. Since multiple sentences can be returned from a comment, I did some manipulation to get back a Series with a row for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  0             Cedi is the GOAT!\n",
       "   1    Isaiah Thomas is the worst\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df = (comment_df['comment'].apply(lambda row: pd.Series(sent_tokenize(row)))\n",
    "                                     .stack())\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to do a bit more `pandas` manipulation to get a DataFrame where the index for each sentence is the same as its parent comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cedi is the GOAT!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isaiah Thomas is the worst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentences\n",
       "level_0                            \n",
       "0                 Cedi is the GOAT!\n",
       "0        Isaiah Thomas is the worst"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df = (sentences_df.reset_index()\n",
    "                  .set_index('level_0')\n",
    "                  .rename(columns={0:'sentences'})\n",
    "                  .drop(['level_1'], axis = 1))\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the index is sorted out, we can rejoin the sentences to the original comments, which allows us to retain metadata like the user and flair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flair</th>\n",
       "      <th>user</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLE</td>\n",
       "      <td>map222</td>\n",
       "      <td>Cedi is the GOAT!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLE</td>\n",
       "      <td>map222</td>\n",
       "      <td>Isaiah Thomas is the worst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flair    user                   sentences\n",
       "0   CLE  map222           Cedi is the GOAT!\n",
       "0   CLE  map222  Isaiah Thomas is the worst"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_df = (comment_df.join(sentences_df)\n",
    "                        .drop(columns = ['comment']))\n",
    "comment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
