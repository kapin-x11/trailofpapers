{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What makes athletes popular? a sentiment and regression analysis\n",
    "## Part III: Regression analysis of sentiment\n",
    "\n",
    "In this project, I am using natural language processing (NLP) to try to understand what factors drive public opinion towards athletes. In [part 1](https://nbviewer.jupyter.org/github/map222/trailofpapers/blob/master/sentiment_sports/paper/scrape_reddit_covariates.ipynb), I showed how to scrape reddit; in [part 2 NNN](https://nbviewer.jupyter.org/github/map222/trailofpapers/blob/master/sentiment_sports/paper/regression_sentiment.ipynb), I showed how to use sentiment analysis to calculate opinion towards players. In this notebook, I will fit regression models to comment sentiment and votes in order to determine which features of an athlete are predictive of sentiment.\n",
    "\n",
    "### How regression allows us to understand underlying factors\n",
    "\n",
    "We know that some athletes are more popular than others, and that athletes differ in their characteristics, both intrinsic (height, age, race), and extrinsic (points scored, yards run). Given that there are dozens of these characteristics, how do we understand which ones make athletes more popular or less?\n",
    "\n",
    "One naive approach would be to graph scatterplots of the relationship between sentiment and characteristics, as we did in part 2. This can be illuminating, and reveal obvious relationships, like how sentiment is higher for young player (NNN show graph). However, age is correlated with many other things; for example, young players usually get less playing time than the average player. Does this mean people prefer players who don't play a lot, or is something else going on? What we need is a technique that can consider all of these characteristics simultaneously.\n",
    "\n",
    "The method we use in the project is to use multi-variate linear regression. This allows you to measure how each characteristic would change sentiment simultaneously, and independently of each other characteristic. For example, if we find that the coefficient for age is -0.1 sentiment points per year of age, we know that no matter what a player's other characteristics are, if we were to increase their age by one year, their measured sentiment would most likely decrease.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation\n",
    "\n",
    "Before describing how we did the regression, let's briefly go over how we aggregate our data. Our raw data comes in the form of sentences about single players by single users. We then aggregate this data taking the mean sentiment towards each player by each user, in a given season. For players, due to the large sample size, we analyze the data at this level; for coaches, we aggregate this data one step further, and calculate the average sentiment towards each coach, across all users, for a given season (a mean of means). In addition to calculating the average sentiment at these levels, we count the number of sentences that went into that average, which we use in weighting later.\n",
    "\n",
    "Here is what our data looks like in aggregated form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\map22\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nba_df = pd.read_csv('c:/Users/map22/Google Drive/sentiment_nba/nba_user_player_sentiment.tsv', sep='\\t')\n",
    "nba_df = nba_df.dropna(subset=['Race', 'PPG']) # get some name matches for years players weren't playing / coaches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>user</th>\n",
       "      <th>season</th>\n",
       "      <th>flair</th>\n",
       "      <th>compound_mean</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>PPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>426694</th>\n",
       "      <td>jermaine o'neal</td>\n",
       "      <td>The_Grand_Wizowd</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bulls</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374829</th>\n",
       "      <td>jamal crawford</td>\n",
       "      <td>runningobsessed</td>\n",
       "      <td>2015</td>\n",
       "      <td>NBA</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>1</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588090</th>\n",
       "      <td>kristaps porzingis</td>\n",
       "      <td>Helicase21</td>\n",
       "      <td>2017</td>\n",
       "      <td>[GSW] JaVale McGee</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Player              user  season               flair  \\\n",
       "426694     jermaine o'neal  The_Grand_Wizowd    2015               Bulls   \n",
       "374829      jamal crawford   runningobsessed    2015                 NBA   \n",
       "588090  kristaps porzingis        Helicase21    2017  [GSW] JaVale McGee   \n",
       "\n",
       "        compound_mean  comment_count   PPG  \n",
       "426694         0.4404              1   NaN  \n",
       "374829         0.0772              1  14.2  \n",
       "588090         0.0000              1  22.7  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_df[['Player', 'user', 'season', 'flair', 'compound_mean', 'comment_count', 'PPG']].sample(3, random_state = 24601)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple regression model: unweighted, unclustered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.formula.api as smf\n",
    "model = smf.wls( formula = 'compound_mean ~ MP + PPG', \\\n",
    "#                       ' PPG +  + total_population+  * white_black_diff + C(Race) * clinton_vote_lead',\n",
    "                data = nba_df,\n",
    "               weights = 1,# / (nba_df['compound_mean_std'] / np.sqrt(fit_df['user_count'])),\n",
    "#                missing='raise'   \n",
    "               ).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>compound_mean</td>  <th>  R-squared:         </th>  <td>   0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   107.4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 24 Feb 2019</td> <th>  Prob (F-statistic):</th>  <td>2.36e-47</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:18:27</td>     <th>  Log-Likelihood:    </th> <td>-2.7156e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>855181</td>      <th>  AIC:               </th>  <td>5.431e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>855178</td>      <th>  BIC:               </th>  <td>5.432e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0699</td> <td>    0.001</td> <td>   74.243</td> <td> 0.000</td> <td>    0.068</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MP</th>        <td>-1.212e-06</td> <td> 6.45e-07</td> <td>   -1.879</td> <td> 0.060</td> <td>-2.48e-06</td> <td> 5.24e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PPG</th>       <td>    0.0007</td> <td> 6.42e-05</td> <td>   11.450</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1042.415</td> <th>  Durbin-Watson:     </th> <td>   1.981</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1166.915</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.044</td>  <th>  Prob(JB):          </th> <td>4.05e-254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.158</td>  <th>  Cond. No.          </th> <td>5.46e+03</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          compound_mean   R-squared:                       0.000\n",
       "Model:                            WLS   Adj. R-squared:                  0.000\n",
       "Method:                 Least Squares   F-statistic:                     107.4\n",
       "Date:                Sun, 24 Feb 2019   Prob (F-statistic):           2.36e-47\n",
       "Time:                        14:18:27   Log-Likelihood:            -2.7156e+05\n",
       "No. Observations:              855181   AIC:                         5.431e+05\n",
       "Df Residuals:                  855178   BIC:                         5.432e+05\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0699      0.001     74.243      0.000       0.068       0.072\n",
       "MP         -1.212e-06   6.45e-07     -1.879      0.060   -2.48e-06    5.24e-08\n",
       "PPG            0.0007   6.42e-05     11.450      0.000       0.001       0.001\n",
       "==============================================================================\n",
       "Omnibus:                     1042.415   Durbin-Watson:                   1.981\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1166.915\n",
       "Skew:                          -0.044   Prob(JB):                    4.05e-254\n",
       "Kurtosis:                       3.158   Cond. No.                     5.46e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.46e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding weighting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding clustering of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
